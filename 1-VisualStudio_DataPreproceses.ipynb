{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2447dc68-8ce7-47e8-97cc-37db41a480e0",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79abdd-8701-4955-99fa-bf1595b0ecf1",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da1122-bc2a-4101-9f8a-f5a1ef900562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a656b1a-d95b-458f-95ad-cbe900b3a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleCSVAnalyzer:\n",
    "    \"\"\"Simple CSV file analyzer - Final Version with fixes\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_folder = r\"C:\\Users\\sit\\Downloads\\Capstone2\\Data\"\n",
    "        self.csv_files = {}\n",
    "        self.final_data = None\n",
    "    \n",
    "    # Step 1: Load ResaleFlat CSV Files\n",
    "    def load_all_csv_files(self):\n",
    "        print(\"Step 1: Loading ResaleFlat CSV files...\")\n",
    "        print(\"=\" * 50)\n",
    "        os.chdir(self.data_folder)\n",
    "        all_files = os.listdir(self.data_folder)\n",
    "\n",
    "        resale_flat_files = [f for f in all_files if f.endswith('.csv') and f.startswith('ResaleFlat')]\n",
    "        if not resale_flat_files:\n",
    "            print(\"‚ùå No CSV files starting with 'ResaleFlat' found!\")\n",
    "            return\n",
    "\n",
    "        print(f\"Found {len(resale_flat_files)} ResaleFlat CSV files:\")\n",
    "        for i, file in enumerate(resale_flat_files, 1):\n",
    "            print(f\"   {i}. {file}\")\n",
    "        \n",
    "        for file_name in resale_flat_files:\n",
    "            try:\n",
    "                data = pd.read_csv(file_name)\n",
    "                # ‚úÖ Force headers uppercase immediately\n",
    "                data.columns = [col.strip().upper() for col in data.columns]\n",
    "                self.csv_files[file_name] = data\n",
    "                print(f\"‚úÖ Loaded: {file_name} | Rows: {len(data):,} | Cols: {len(data.columns)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to load {file_name}: {e}\")\n",
    "    \n",
    "    # Step 4: Fix AGE Columns\n",
    "    def fix_age_columns(self):\n",
    "        print(\"\\nStep 4: Fixing AGE columns...\")\n",
    "        print(\"=\" * 50)\n",
    "        current_year = datetime.now().year\n",
    "\n",
    "        for file_name, data in self.csv_files.items():\n",
    "            if 'REMAINING_LEASE' in data.columns:\n",
    "                # Directly compute AGE from numeric REMAINING_LEASE\n",
    "                # Clean and convert REMAINING_LEASE to numeric\n",
    "                data['REMAINING_LEASE'] = pd.to_numeric(data['REMAINING_LEASE'], errors='coerce')\n",
    "                data['AGE'] = (99 - data['REMAINING_LEASE']).fillna(0).astype(int)\n",
    "                print(f\"   ‚úÖ Created AGE from REMAINING_LEASE in {file_name}\")\n",
    "\n",
    "            elif 'LEASE_COMMENCE_DATE' in data.columns:\n",
    "                # Clean and convert LEASE_COMMENCE_DATE to numeric\n",
    "                data['LEASE_COMMENCE_DATE'] = pd.to_numeric(data['LEASE_COMMENCE_DATE'], errors='coerce')               \n",
    "                data['AGE'] = (current_year - data['LEASE_COMMENCE_DATE']).astype(int)\n",
    "                print(f\"   ‚úÖ Created AGE from LEASE_COMMENCE_DATE in {file_name}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è No lease columns found in {file_name}\")\n",
    "    \n",
    "    # Step 6: Clean Text Columns\n",
    "    def clean_text_columns(self):\n",
    "        print(\"\\nStep 6: Converting text to uppercase...\")\n",
    "        print(\"=\" * 50)\n",
    "        text_columns = ['TOWN', 'FLAT_TYPE', 'STREET_NAME', 'FLAT_MODEL']\n",
    "        for file_name, data in self.csv_files.items():\n",
    "            for col in text_columns:\n",
    "                if col in data.columns:\n",
    "                    data[col] = data[col].astype(str).str.upper()\n",
    "                    data[col] = data[col].replace('NAN', pd.NA)\n",
    "                    print(f\"   ‚úÖ Converted {col} to uppercase in {file_name}\")\n",
    "\n",
    "    # Step 7: Combine All Files\n",
    "    def combine_all_files(self):\n",
    "        print(\"\\nStep 7: Combining all files...\")\n",
    "        print(\"=\" * 50)\n",
    "        dfs = []\n",
    "        for file_name, data in self.csv_files.items():\n",
    "            data['SOURCE_FILE'] = file_name\n",
    "            dfs.append(data)\n",
    "        self.final_data = pd.concat(dfs, ignore_index=True)\n",
    "     \n",
    "       # Convert to int for RESALE_PRICE and FLOOR_AREA_SQM\n",
    "        self.final_data['RESALE_PRICE'] = self.final_data['RESALE_PRICE'].fillna(0).astype(int)\n",
    "        self.final_data['FLOOR_AREA_SQM'] = self.final_data['FLOOR_AREA_SQM'].fillna(0).astype(int)\n",
    "        print(f\"‚úÖ Combined successfully! Rows: {len(self.final_data):,}, Cols: {len(self.final_data.columns)}\")\n",
    "\n",
    "    # Step 8: Split MONTH Field\n",
    "    def split_month_field(self):\n",
    "        print(\"\\nStep 8: Splitting MONTH field...\")\n",
    "        print(\"=\" * 50)\n",
    "        if self.final_data is None:\n",
    "            print(\"‚ùå No data available\")\n",
    "            return\n",
    "        if 'MONTH' not in self.final_data.columns:\n",
    "            print(\"‚ùå MONTH column not found\")\n",
    "            return\n",
    "\n",
    "        print(\"Sample MONTH values:\", self.final_data['MONTH'].dropna().head(5).tolist())\n",
    "        try:\n",
    "            self.final_data['MONTH'] = pd.to_datetime(self.final_data['MONTH'], errors='coerce')\n",
    "            self.final_data['YEAR'] = self.final_data['MONTH'].dt.year\n",
    "            self.final_data['MONTH_NUM'] = self.final_data['MONTH'].dt.month\n",
    "            print(\"‚úÖ Successfully split MONTH into YEAR and MONTH_NUM\")\n",
    "            print(self.final_data[['MONTH', 'YEAR', 'MONTH_NUM']].head())\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error splitting MONTH field: {e}\")\n",
    "\n",
    "    # Step 9: Create Filtered Dataset\n",
    "    def create_filtered_dataset(self):\n",
    "        print(\"\\nStep 9: Creating filtered dataset...\")\n",
    "        print(\"=\" * 50)\n",
    "        if self.final_data is None:\n",
    "            print(\"‚ùå No data available\")\n",
    "            return\n",
    "        exclude_cols = ['STREET_NAME', 'SOURCE_FILE', 'LEASE_COMMENCE_DATE','MONTH','REMAINING_LEASE','REMAINING_LEASE_YEARS','BLOCK']\n",
    "        keep_cols = [c for c in self.final_data.columns if c not in exclude_cols]\n",
    "        self.final_data = self.final_data[keep_cols].copy()\n",
    "        print(f\"‚úÖ Filtered dataset created. Cols left: {len(self.final_data.columns)}\")\n",
    "\n",
    "    # Step 10: Show Sample Data\n",
    "    def show_sample_data(self):\n",
    "        print(\"\\nStep 10: Sample of filtered data...\")\n",
    "        print(\"=\" * 50)\n",
    "        if self.final_data is not None:\n",
    "            print(self.final_data.head(3))\n",
    "            print(\"\\nColumns:\", list(self.final_data.columns))\n",
    "\n",
    "    # Step 11: Check for Duplicate Data\n",
    "    def check_duplicate_data(self):\n",
    "        print(\"\\nStep 11: Checking for duplicate rows...\")\n",
    "        print(\"=\" * 50)\n",
    "        if self.final_data is None:\n",
    "            print(\"‚ùå No data available\")\n",
    "            return\n",
    "\n",
    "        # Step 1: Detect duplicates\n",
    "        duplicate_rows = self.final_data[self.final_data.duplicated()]\n",
    "        num_duplicates = len(duplicate_rows)\n",
    "\n",
    "        if num_duplicates > 0:\n",
    "            print(f\"üîç Found {num_duplicates:,} duplicate rows.\")\n",
    "            print(\"Here are a few examples:\")\n",
    "            print(duplicate_rows.head(3))\n",
    "\n",
    "            # Step 2: Drop duplicates\n",
    "            self.final_data = self.final_data.drop_duplicates()\n",
    "            print(f\"üßπ Dropped duplicates. Remaining rows: {len(self.final_data):,}\")\n",
    "\n",
    "            # Step 3: Re-check for any remaining duplicates\n",
    "            remaining_duplicates = self.final_data[self.final_data.duplicated()]\n",
    "            if len(remaining_duplicates) == 0:\n",
    "                print(\"‚úÖ No duplicate rows remain after cleanup.\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Still found {len(remaining_duplicates):,} duplicates after drop.\")\n",
    "                print(remaining_duplicates.head(3))\n",
    "        else:\n",
    "            print(\"‚úÖ No duplicate rows found.\")\n",
    "\n",
    "\n",
    "    # Step 12: Export Final Data\n",
    "    def save_final_data(self, output_filename=\"final_resale_data.csv\"):\n",
    "        print(\"\\nStep 11: Saving final dataset...\")\n",
    "        print(\"=\" * 50)\n",
    "        if self.final_data is not None:\n",
    "            output_path = os.path.join(self.data_folder, output_filename)\n",
    "            self.final_data.to_csv(output_path, index=False)\n",
    "            print(f\"‚úÖ Saved final dataset to {output_path}\")\n",
    "        else:\n",
    "            print(\"‚ùå No data to save\")\n",
    "            \n",
    "\n",
    "    # Run All Steps\n",
    "    def run_complete_analysis(self):\n",
    "        print(\"üöÄ Starting Complete CSV Analysis\")\n",
    "        print(\"=\" * 70)\n",
    "        self.load_all_csv_files()\n",
    "        if not self.csv_files:\n",
    "            return\n",
    "        self.fix_age_columns()\n",
    "        self.clean_text_columns()\n",
    "        self.combine_all_files()\n",
    "        self.split_month_field()\n",
    "        self.create_filtered_dataset()\n",
    "        self.show_sample_data()\n",
    "        self.check_duplicate_data()\n",
    "    #    self.save_final_data()  # Uncomment if you want auto-save\n",
    "        print(\"\\nüéâ Analysis Complete! \")\n",
    "\n",
    "def main():\n",
    "    analyzer = SimpleCSVAnalyzer()\n",
    "    analyzer.run_complete_analysis()\n",
    "    return analyzer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38094bc1-ecf8-4b40-8dbe-10106ab4961f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3011902535.py, line 12)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdf = pd.read_csv('C:\\Users\\sit\\Downloads\\Capstone2\\Sample\\hdb_data.csv')\u001b[39m\n                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# EDA on Singapore HDB Resale Price Dataset\n",
    "# Objective: Analyze numerical and categorical features vs RESALE_PRICE\n",
    "# and detect outliers with recommendations.\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:\\Users\\sit\\Downloads\\Capstone2\\Sample\\hdb_data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Sample Data:\")\n",
    "display(df.head())\n",
    "\n",
    "# Define numerical and categorical columns\n",
    "num_attribs = [\"AGE\", \"FLOOR_AREA_SQM\", \"YEAR\", \"MONTH_NUM\"]\n",
    "cat_attribs = [\"TOWN\", \"FLAT_TYPE\", \"STOREY_RANGE\", \"FLAT_MODEL\"]\n",
    "\n",
    "# Basic info and stats\n",
    "print(\"\\nData Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nDescriptive statistics for numerical attributes:\")\n",
    "display(df[num_attribs + [\"RESALE_PRICE\"]].describe())\n",
    "\n",
    "print(\"\\nUnique values in categorical attributes:\")\n",
    "for col in cat_attribs:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "# ======================\n",
    "# 1. Scatterplots for Numerical Features vs RESALE_PRICE\n",
    "# ======================\n",
    "print(\"\\nScatterplots: Numerical attributes vs RESALE_PRICE\")\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, col in enumerate(num_attribs):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.scatterplot(data=df.sample(5000, random_state=42), x=col, y=\"RESALE_PRICE\", alpha=0.3)\n",
    "    plt.title(f\"{col} vs RESALE_PRICE\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ======================\n",
    "# 2. Boxplots for Categorical Features vs RESALE_PRICE\n",
    "# ======================\n",
    "print(\"\\nBoxplots: Categorical attributes vs RESALE_PRICE\")\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, col in enumerate(cat_attribs):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.boxplot(data=df.sample(5000, random_state=42), x=col, y=\"RESALE_PRICE\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f\"{col} vs RESALE_PRICE\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ======================\n",
    "# 3. Outlier Detection\n",
    "# ======================\n",
    "\n",
    "# Use IQR method on RESALE_PRICE\n",
    "Q1 = df[\"RESALE_PRICE\"].quantile(0.25)\n",
    "Q3 = df[\"RESALE_PRICE\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df[\"RESALE_PRICE\"] < lower_bound) | (df[\"RESALE_PRICE\"] > upper_bound)]\n",
    "print(f\"\\nNumber of outliers detected in RESALE_PRICE: {outliers.shape[0]}\")\n",
    "\n",
    "# Display summary stats for outliers\n",
    "print(\"\\nSummary statistics for outliers:\")\n",
    "display(outliers.describe())\n",
    "\n",
    "# Outlier detection for numerical features vs RESALE_PRICE (using boxplot stats)\n",
    "for col in num_attribs:\n",
    "    Q1_col = df[col].quantile(0.25)\n",
    "    Q3_col = df[col].quantile(0.75)\n",
    "    IQR_col = Q3_col - Q1_col\n",
    "    lower_col = Q1_col - 1.5 * IQR_col\n",
    "    upper_col = Q3_col + 1.5 * IQR_col\n",
    "    col_outliers = df[(df[col] < lower_col) | (df[col] > upper_col)]\n",
    "    print(f\"\\nOutliers in {col}: {col_outliers.shape[0]} rows\")\n",
    "\n",
    "# ======================\n",
    "# Recommendations for Outliers\n",
    "# ======================\n",
    "print(\"\"\"\n",
    "Recommendations on Outliers:\n",
    "\n",
    "1. RESALE_PRICE Outliers:\n",
    "   - Some extreme resale prices could be data entry errors or very unique properties.\n",
    "   - Consider:\n",
    "       * Investigate and verify outlier records if possible.\n",
    "       * Remove extreme outliers if they skew the model.\n",
    "       * Alternatively, use robust regression models less sensitive to outliers.\n",
    "       * Apply transformations (e.g., log) on RESALE_PRICE to reduce skewness.\n",
    "\n",
    "2. Numerical Attributes Outliers:\n",
    "   - For AGE and FLOOR_AREA_SQM, extreme values may be valid but rare.\n",
    "   - Check if outliers correspond to valid flats (e.g., very old age or very large floor area).\n",
    "   - You may cap values at reasonable percentiles (e.g., 1st and 99th percentiles) if they harm model performance.\n",
    "\n",
    "3. Categorical Attributes:\n",
    "   - Rare categories with very few data points might be grouped as 'Others' to reduce noise.\n",
    "\n",
    "4. General:\n",
    "   - Use visualizations and domain knowledge to decide on outlier treatment.\n",
    "   - Consider feature scaling and transformation for numerical columns before modeling.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47fbab1-fecd-4c5b-9470-3a7a48888aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6811f51-2f08-4100-ac9d-0a146ae8d50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
