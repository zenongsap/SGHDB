{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature : Price Estimate using CatBoost with best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Applying one-hot encoding on: ['TOWN', 'FLAT_TYPE']\n",
      "âœ… One-hot encoding complete.\n",
      "ðŸ“Œ Encoded columns preview: ['FLOOR_AREA_SQM', 'RESALE_PRICE', 'AGE', 'YEAR', 'STOREY_NUMERIC', 'DATE_IDX', 'TOWN_ANG MO KIO', 'TOWN_BEDOK', 'TOWN_BISHAN', 'TOWN_BUKIT BATOK', 'TOWN_BUKIT MERAH', 'TOWN_BUKIT PANJANG', 'TOWN_BUKIT TIMAH', 'TOWN_CENTRAL AREA', 'TOWN_CHOA CHU KANG', 'TOWN_CLEMENTI', 'TOWN_GEYLANG', 'TOWN_HOUGANG', 'TOWN_JURONG EAST', 'TOWN_JURONG WEST']\n",
      "   FLOOR_AREA_SQM  RESALE_PRICE  AGE  YEAR  STOREY_NUMERIC  DATE_IDX  \\\n",
      "0              59     12.842652   50  2012               8     24150   \n",
      "1              65     12.906694   50  2012               8     24150   \n",
      "2              65     12.945629   50  2012               8     24150   \n",
      "3              65     12.985400   50  2012               8     24150   \n",
      "4              68     12.994532   49  2012               8     24150   \n",
      "\n",
      "   TOWN_ANG MO KIO  TOWN_BEDOK  TOWN_BISHAN  TOWN_BUKIT BATOK  ...  \\\n",
      "0                0           0            0                 0  ...   \n",
      "1                0           0            0                 0  ...   \n",
      "2                0           0            0                 0  ...   \n",
      "3                0           0            0                 0  ...   \n",
      "4                0           0            0                 0  ...   \n",
      "\n",
      "   TOWN_SERANGOON  TOWN_TAMPINES  TOWN_TOA PAYOH  TOWN_WOODLANDS  TOWN_YISHUN  \\\n",
      "0               0              0               0               0            0   \n",
      "1               0              0               0               0            0   \n",
      "2               0              0               0               0            0   \n",
      "3               0              0               0               0            0   \n",
      "4               0              0               0               0            0   \n",
      "\n",
      "   FLAT_TYPE_3 ROOM  FLAT_TYPE_4 ROOM  FLAT_TYPE_5 ROOM  FLAT_TYPE_EXECUTIVE  \\\n",
      "0                 1                 0                 0                    0   \n",
      "1                 1                 0                 0                    0   \n",
      "2                 1                 0                 0                    0   \n",
      "3                 1                 0                 0                    0   \n",
      "4                 1                 0                 0                    0   \n",
      "\n",
      "   FLAT_TYPE_MULTI-GENERATION  \n",
      "0                           0  \n",
      "1                           0  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           0  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "âœ… train set numeric dtypes: int32    31\n",
      "int64     5\n",
      "Name: count, dtype: int64\n",
      "âœ… valid set numeric dtypes: int32    31\n",
      "int64     5\n",
      "Name: count, dtype: int64\n",
      "âœ… test set numeric dtypes: int32    31\n",
      "int64     5\n",
      "Name: count, dtype: int64\n",
      "11:32:04 \n",
      "âœ… Data ready for training (train/valid/test) - 11:32:04\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "# ========================================================\n",
    "# 1. Load data\n",
    "# =======================================================\n",
    "df = pd.read_csv('raw_data_main.csv')\n",
    "\n",
    "# Exclude outliers (remove rows where IS_OUTLIERS = 1)\n",
    "df = df[df['IS_OUTLIERS'] != 1]\n",
    "\n",
    "# Create DATE_IDX (optional)\n",
    "df['DATE_IDX'] = df['YEAR'] * 12 + df['MONTH_NUM']\n",
    "\n",
    "# Log-transform target\n",
    "df['RESALE_PRICE'] = np.log1p(df['RESALE_PRICE'])\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. Drop unwanted columns BEFORE preparing features\n",
    "# --------------------------------------------------------\n",
    "drop_cols = ['IS_OUTLIERS', 'STOREY_RANGE', 'PRICE_PER_SQM', 'MONTH_NUM','PRICE_TIER','SEASON','AGE_GROUP']\n",
    "df = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Define categorical variables to encode\n",
    "categorical_cols = ['TOWN', 'FLAT_TYPE']\n",
    "categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "print(f\"ðŸ“Œ Applying one-hot encoding on: {categorical_cols}\")\n",
    "df = pd.get_dummies(df, columns=categorical_cols, dtype=int)\n",
    "print(\"âœ… One-hot encoding complete.\")\n",
    "print(\"ðŸ“Œ Encoded columns preview:\", df.columns.tolist()[:20])\n",
    "print(df.head())\n",
    "\n",
    "# Optional: sample smaller subset for quick experiments\n",
    "#df = df.sample(20000, random_state=42)\n",
    "\n",
    "# Create bin for stratified sampling\n",
    "df['price_bin'] = pd.qcut(df['RESALE_PRICE'], q=4, labels=False)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. Train / Validation / Test split\n",
    "# --------------------------------------------------------\n",
    "df_trainval, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['price_bin'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_train, df_valid = train_test_split(\n",
    "    df_trainval,\n",
    "    test_size=0.25,\n",
    "    stratify=df_trainval['price_bin'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Drop helper column used for stratification\n",
    "df_train = df_train.drop(columns=['price_bin'])\n",
    "df_valid = df_valid.drop(columns=['price_bin'])\n",
    "df_test  = df_test.drop(columns=['price_bin'])\n",
    "\n",
    "# ========================================================\n",
    "# 4. Prepare features and target (no further dropping needed)\n",
    "# ========================================================\n",
    "X_train = df_train.drop(columns=['RESALE_PRICE'])\n",
    "y_train = df_train['RESALE_PRICE']\n",
    "\n",
    "X_valid = df_valid.drop(columns=['RESALE_PRICE'])\n",
    "y_valid = df_valid['RESALE_PRICE']\n",
    "\n",
    "X_test  = df_test.drop(columns=['RESALE_PRICE'])\n",
    "y_test  = df_test['RESALE_PRICE']\n",
    "\n",
    "# Ensure all numeric\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "X_valid = X_valid.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "X_test  = X_test.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# Optional: sanity check\n",
    "for name, dfX in [(\"train\", X_train), (\"valid\", X_valid), (\"test\", X_test)]:\n",
    "    print(f\"âœ… {name} set numeric dtypes:\", dfX.dtypes.value_counts())\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "print(f\"{timestamp} \\nâœ… Data ready for training (train/valid/test) - {timestamp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime  # Make sure you have this imported\n",
    "\n",
    "def evaluate(model, X, y, label=\"Model\"):\n",
    "    preds = np.expm1(model.predict(X))\n",
    "    y_true = np.expm1(y)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, preds))\n",
    "    mae = mean_absolute_error(y_true, preds)\n",
    "    r2 = r2_score(y_true, preds)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š {label} Test Metrics at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}:\")\n",
    "    print(f\"RMSE: {rmse:,.2f} | MAE: {mae:,.2f} | RÂ²: {r2:.4f}\")\n",
    "    \n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2925791\ttest: 0.2936916\tbest: 0.2936916 (0)\ttotal: 168ms\tremaining: 4m 27s\n",
      "1000:\tlearn: 0.0658374\ttest: 0.0681861\tbest: 0.0681861 (1000)\ttotal: 17.3s\tremaining: 10.2s\n",
      "1593:\tlearn: 0.0629804\ttest: 0.0662806\tbest: 0.0662806 (1593)\ttotal: 30.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.06628056504\n",
      "bestIteration = 1593\n",
      "\n",
      "\n",
      "ðŸ“Š CatBoost Validation Test Metrics at 2025-09-23 11:32:50:\n",
      "RMSE: 35,249.68 | MAE: 24,942.93 | RÂ²: 0.9541\n",
      "\n",
      "ðŸ“Š Validation Results\n",
      "RMSE: 35,249.68 | MAE: 24,942.93 | RÂ²: 0.9541\n",
      "âœ… Trained CatBoost model saved to 'catboost_model_valid.pkl'\n",
      "âœ… Updated 'best_catboost_params.json' with feature names\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# ðŸ§  Load best CatBoost parameters and train model\n",
    "# ========================================================\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load best parameters from JSON\n",
    "with open(\"best_catboost_params.json\", \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "# Remove RÂ² score from params dict if it exists\n",
    "best_params.pop('r2', None)\n",
    "\n",
    "# 2. Train the model on X_train\n",
    "model = CatBoostRegressor(\n",
    "    verbose=1000,\n",
    "    random_state=42,\n",
    "    loss_function='RMSE',\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_valid, y_valid),\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# 3. Predict on validation set\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "# 4. Evaluate model\n",
    "rmse, mae, r2 = evaluate(model, X_valid, y_valid, label=\"CatBoost Validation\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Validation Results\")\n",
    "print(f\"RMSE: {rmse:,.2f} | MAE: {mae:,.2f} | RÂ²: {r2:.4f}\")\n",
    "\n",
    "# 5. (Optional) Save the trained model\n",
    "joblib.dump(model, \"catboost_model_valid.pkl\")\n",
    "print(\"âœ… Trained CatBoost model saved to 'catboost_model_valid.pkl'\")\n",
    "\n",
    "# 6. Save the feature names used during training\n",
    "features_used = X_train.columns.tolist()\n",
    "best_params['features_used'] = features_used\n",
    "with open(\"best_catboost_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f)\n",
    "print(\"âœ… Updated 'best_catboost_params.json' with feature names\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CatBoost_features_used.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the list of features actually used in the model\n",
    "joblib.dump(features_used, \"CatBoost_features_used.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Applying one-hot encoding on: ['TOWN', 'FLAT_TYPE']\n",
      "âœ… One-hot encoding complete.\n",
      "ðŸ“Œ Encoded columns preview: ['FLOOR_AREA_SQM', 'RESALE_PRICE', 'AGE', 'STOREY_NUMERIC', 'DATE_IDX', 'TOWN_ANG MO KIO', 'TOWN_BEDOK', 'TOWN_BISHAN', 'TOWN_BUKIT BATOK', 'TOWN_BUKIT MERAH', 'TOWN_BUKIT PANJANG', 'TOWN_BUKIT TIMAH', 'TOWN_CENTRAL AREA', 'TOWN_CHOA CHU KANG', 'TOWN_CLEMENTI', 'TOWN_GEYLANG', 'TOWN_HOUGANG', 'TOWN_JURONG EAST', 'TOWN_JURONG WEST', 'TOWN_KALLANG/WHAMPOA']\n",
      "   FLOOR_AREA_SQM  RESALE_PRICE  AGE  STOREY_NUMERIC  DATE_IDX  \\\n",
      "0              67     12.868763   44              11     24153   \n",
      "1              70     12.886644   49               8     24153   \n",
      "2              59     12.889172   54               5     24153   \n",
      "3              67     12.906694   43               8     24153   \n",
      "4              67     12.911645   49              11     24153   \n",
      "\n",
      "   TOWN_ANG MO KIO  TOWN_BEDOK  TOWN_BISHAN  TOWN_BUKIT BATOK  \\\n",
      "0                0           0            0                 0   \n",
      "1                0           0            0                 0   \n",
      "2                0           0            0                 0   \n",
      "3                0           0            0                 0   \n",
      "4                0           0            0                 0   \n",
      "\n",
      "   TOWN_BUKIT MERAH  ...  TOWN_SERANGOON  TOWN_TAMPINES  TOWN_TOA PAYOH  \\\n",
      "0                 1  ...               0              0               0   \n",
      "1                 1  ...               0              0               0   \n",
      "2                 1  ...               0              0               0   \n",
      "3                 1  ...               0              0               0   \n",
      "4                 1  ...               0              0               0   \n",
      "\n",
      "   TOWN_WOODLANDS  TOWN_YISHUN  FLAT_TYPE_3 ROOM  FLAT_TYPE_4 ROOM  \\\n",
      "0               0            0                 1                 0   \n",
      "1               0            0                 1                 0   \n",
      "2               0            0                 1                 0   \n",
      "3               0            0                 1                 0   \n",
      "4               0            0                 1                 0   \n",
      "\n",
      "   FLAT_TYPE_5 ROOM  FLAT_TYPE_EXECUTIVE  FLAT_TYPE_MULTI-GENERATION  \n",
      "0                 0                    0                           0  \n",
      "1                 0                    0                           0  \n",
      "2                 0                    0                           0  \n",
      "3                 0                    0                           0  \n",
      "4                 0                    0                           0  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "âœ… train set numeric dtypes: int32    31\n",
      "int64     4\n",
      "Name: count, dtype: int64\n",
      "âœ… valid set numeric dtypes: int32    31\n",
      "int64     4\n",
      "Name: count, dtype: int64\n",
      "âœ… test set numeric dtypes: int32    31\n",
      "int64     4\n",
      "Name: count, dtype: int64\n",
      "âœ… Data ready for training (train/valid/test) - 10:17:36\n",
      "0:\tlearn: 0.3077040\ttest: 0.3073338\tbest: 0.3073338 (0)\ttotal: 122ms\tremaining: 3m 15s\n",
      "100:\tlearn: 0.1044238\ttest: 0.1061329\tbest: 0.1061329 (100)\ttotal: 12.6s\tremaining: 3m 6s\n",
      "200:\tlearn: 0.0935968\ttest: 0.0958901\tbest: 0.0958901 (200)\ttotal: 19.5s\tremaining: 2m 16s\n",
      "300:\tlearn: 0.0880070\ttest: 0.0911531\tbest: 0.0911531 (300)\ttotal: 27.9s\tremaining: 2m\n",
      "400:\tlearn: 0.0850883\ttest: 0.0890458\tbest: 0.0890458 (400)\ttotal: 38.3s\tremaining: 1m 54s\n",
      "500:\tlearn: 0.0827471\ttest: 0.0875207\tbest: 0.0875207 (500)\ttotal: 48.4s\tremaining: 1m 46s\n",
      "600:\tlearn: 0.0812922\ttest: 0.0867351\tbest: 0.0867350 (599)\ttotal: 57.9s\tremaining: 1m 36s\n",
      "700:\tlearn: 0.0800661\ttest: 0.0861268\tbest: 0.0861268 (700)\ttotal: 1m 6s\tremaining: 1m 25s\n",
      "800:\tlearn: 0.0788799\ttest: 0.0855719\tbest: 0.0855719 (800)\ttotal: 1m 14s\tremaining: 1m 14s\n",
      "900:\tlearn: 0.0779249\ttest: 0.0852088\tbest: 0.0852088 (900)\ttotal: 1m 22s\tremaining: 1m 4s\n",
      "1000:\tlearn: 0.0769717\ttest: 0.0849024\tbest: 0.0849024 (1000)\ttotal: 1m 30s\tremaining: 54.1s\n",
      "1100:\tlearn: 0.0762780\ttest: 0.0847004\tbest: 0.0847004 (1100)\ttotal: 1m 37s\tremaining: 44.4s\n",
      "1200:\tlearn: 0.0756241\ttest: 0.0845382\tbest: 0.0845377 (1199)\ttotal: 1m 45s\tremaining: 35.2s\n",
      "1300:\tlearn: 0.0749428\ttest: 0.0843611\tbest: 0.0843611 (1300)\ttotal: 1m 52s\tremaining: 25.9s\n",
      "1400:\tlearn: 0.0744031\ttest: 0.0842471\tbest: 0.0842469 (1397)\ttotal: 1m 59s\tremaining: 17s\n",
      "1500:\tlearn: 0.0739516\ttest: 0.0841908\tbest: 0.0841906 (1497)\ttotal: 2m 5s\tremaining: 8.29s\n",
      "1599:\tlearn: 0.0734652\ttest: 0.0841157\tbest: 0.0841157 (1599)\ttotal: 2m 11s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.08411574313\n",
      "bestIteration = 1599\n",
      "\n",
      "\n",
      "ðŸ“Š CatBoost Training Results (Actual Price Scale)\n",
      "RMSE: 38,872.90 | MAE: 26,154.17 | RÂ²: 0.9472\n",
      "\n",
      "ðŸ“Š CatBoost Validation Results (Actual Price Scale)\n",
      "RMSE: 45,318.27 | MAE: 30,245.64 | RÂ²: 0.9279\n",
      "\n",
      "ðŸ“Š CatBoost Test Results (Actual Price Scale)\n",
      "RMSE: 45,375.76 | MAE: 30,369.89 | RÂ²: 0.9284\n",
      "âœ… Trained CatBoost model saved to 'catboost_model_valid_test.pkl'\n"
     ]
    }
   ],
   "source": [
    "# ========================================================\n",
    "# ðŸ§  Train with different years and data size combination with best CatBoost parameters \n",
    "# ========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# ========================================================\n",
    "# 1. Load data & Filter by year\n",
    "# ========================================================\n",
    "df = pd.read_csv('raw_data_main.csv')\n",
    "\n",
    "# --- Filter data for years 2020 to 2025 ---\n",
    "# df = df[(df['YEAR'] >= 2015) & (df['YEAR'] <= 2025)].copy()\n",
    "# The .copy() ensures we're working on a new DataFrame to avoid a SettingWithCopyWarning.\n",
    "\n",
    "# Create DATE_IDX (optional)\n",
    "df['DATE_IDX'] = df['YEAR'] * 12 + df['MONTH_NUM']\n",
    "\n",
    "# Log-transform target\n",
    "df['RESALE_PRICE'] = np.log1p(df['RESALE_PRICE'])\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. Drop unwanted columns BEFORE preparing features\n",
    "# --------------------------------------------------------\n",
    "drop_cols = ['IS_OUTLIERS', 'STOREY_RANGE', 'PRICE_PER_SQM', 'YEAR', 'MONTH_NUM','PRICE_TIER','SEASON','AGE_GROUP']\n",
    "df = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Define categorical variables to encode\n",
    "categorical_cols = ['TOWN', 'FLAT_TYPE']\n",
    "categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "print(f\"ðŸ“Œ Applying one-hot encoding on: {categorical_cols}\")\n",
    "df = pd.get_dummies(df, columns=categorical_cols, dtype=int)\n",
    "print(\"âœ… One-hot encoding complete.\")\n",
    "print(\"ðŸ“Œ Encoded columns preview:\", df.columns.tolist()[:20])\n",
    "print(df.head())\n",
    "\n",
    "# Optional: sample smaller subset for quick experiments\n",
    "#df = df.sample(min(100000, len(df)), random_state=42)\n",
    "# Updated to handle datasets smaller than 100k\n",
    "\n",
    "# Create bin for stratified sampling\n",
    "df['price_bin'] = pd.qcut(df['RESALE_PRICE'], q=4, labels=False)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. Train / Validation / Test split\n",
    "# --------------------------------------------------------\n",
    "df_trainval, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['price_bin'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_train, df_valid = train_test_split(\n",
    "    df_trainval,\n",
    "    test_size=0.25,\n",
    "    stratify=df_trainval['price_bin'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Drop helper column used for stratification\n",
    "df_train = df_train.drop(columns=['price_bin'])\n",
    "df_valid = df_valid.drop(columns=['price_bin'])\n",
    "df_test = df_test.drop(columns=['price_bin'])\n",
    "\n",
    "# ========================================================\n",
    "# 4. Prepare features and target (no further dropping needed)\n",
    "# ========================================================\n",
    "X_train = df_train.drop(columns=['RESALE_PRICE'])\n",
    "y_train = df_train['RESALE_PRICE']\n",
    "\n",
    "X_valid = df_valid.drop(columns=['RESALE_PRICE'])\n",
    "y_valid = df_valid['RESALE_PRICE']\n",
    "\n",
    "X_test = df_test.drop(columns=['RESALE_PRICE'])\n",
    "y_test = df_test['RESALE_PRICE']\n",
    "\n",
    "# Ensure all numeric\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "X_valid = X_valid.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# Optional: sanity check\n",
    "for name, dfX in [(\"train\", X_train), (\"valid\", X_valid), (\"test\", X_test)]:\n",
    "    print(f\"âœ… {name} set numeric dtypes:\", dfX.dtypes.value_counts())\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "print(f\"âœ… Data ready for training (train/valid/test) - {timestamp}\")\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "# 5. Load best CatBoost parameters and train model\n",
    "# ========================================================\n",
    "'''\n",
    "def evaluate(model, X, y, label=\"\"):\n",
    "    \"\"\"Helper function to evaluate the model and print metrics.\"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š {label} Results\")\n",
    "    print(f\"RMSE: {rmse:,.2f} | MAE: {mae:,.2f} | RÂ²: {r2:.4f}\")\n",
    "    return rmse, mae, r2\n",
    "'''\n",
    "def evaluate_actual_scale(model, X, y_log, label=\"\"):\n",
    "    \"\"\"Evaluate model predictions in original price scale.\"\"\"\n",
    "    # Inverse transform\n",
    "    y_pred_log = model.predict(X)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_true = np.expm1(y_log)\n",
    "\n",
    "    # Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nðŸ“Š {label} Results (Actual Price Scale)\")\n",
    "    print(f\"RMSE: {rmse:,.2f} | MAE: {mae:,.2f} | RÂ²: {r2:.4f}\")\n",
    "    return rmse, mae, r2\n",
    "    \n",
    "# 1. Load best parameters from JSON\n",
    "with open(\"best_catboost_params.json\", \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "# Remove RÂ² score from params dict if it exists\n",
    "best_params.pop('r2', None)\n",
    "\n",
    "# 2. Train the model on X_train\n",
    "model = CatBoostRegressor(\n",
    "    verbose=100, # Reduced verbosity for cleaner output\n",
    "    random_state=42,\n",
    "    loss_function='RMSE',\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_valid, y_valid),\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# 3. Predict on validation set & Evaluate model\n",
    "# evaluate(model, X_valid, y_valid, label=\"CatBoost Validation\")\n",
    "\n",
    "# Training set\n",
    "evaluate_actual_scale(model, X_train, y_train, label=\"CatBoost Training\")\n",
    "\n",
    "# Validation set\n",
    "evaluate_actual_scale(model, X_valid, y_valid, label=\"CatBoost Validation\")\n",
    "\n",
    "# Test set\n",
    "evaluate_actual_scale(model, X_test, y_test, label=\"CatBoost Test\")\n",
    "\n",
    "\n",
    "# 4. Save the trained model\n",
    "joblib.dump(model, \"catboost_model_valid_test.pkl\")\n",
    "print(\"âœ… Trained CatBoost model saved to 'catboost_model_valid_test.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
